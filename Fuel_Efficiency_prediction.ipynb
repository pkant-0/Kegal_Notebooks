{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8898225,
          "sourceType": "datasetVersion",
          "datasetId": 5349799
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Fuel_Efficiency_prediction",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkant-0/Kegal_Notebooks/blob/main/Fuel_Efficiency_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'auto-mpg:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5349799%2F8898225%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240708%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240708T152334Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D33fdfc0bb5d7a1ea650fd441613cacc01652eee1509b0d7a18b643e53411f249a3252fcb1427e95fc732f09f16b4753fa4239f1c2a798cf7c877c20a4b9fde9bc8c39f6458279470f67142c13fdf2eae1863b7806fc9cdc30a1111378d50ea718f1b241ef92419bef21dfa8da381a37fe13133c3877dd1328ebfde024351f02ce3daf64307bb8b6e2bc5e464a6833a09312b212dee8757291c10d2bd0419f4bdb9fe49411611a9554e0a585882d7ad8303a30581e4799adbf328de6252b7f073dd5a51821cdc11f0e7406bc129aab60dc83428ad5cc60a239130149c96e1582f1ee5fbe94cc524bb900d6e004ce4995f562ee9c3d09c1f9ff903159e0196964a'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "naiIl1zl8bzu"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fuel Efficiency Prediction - Regression Using the Auto MPG dataset**\n",
        "\n"
      ],
      "metadata": {
        "id": "jyBR8moM8bz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# User Seaborn for pairplot\n",
        "!pip install seaborn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:14:10.126134Z",
          "iopub.execute_input": "2024-07-07T15:14:10.127268Z",
          "iopub.status.idle": "2024-07-07T15:14:47.539682Z",
          "shell.execute_reply.started": "2024-07-07T15:14:10.127224Z",
          "shell.execute_reply": "2024-07-07T15:14:47.538177Z"
        },
        "trusted": true,
        "id": "WUcfu9CM8bz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:17:25.944458Z",
          "iopub.execute_input": "2024-07-07T15:17:25.944942Z",
          "iopub.status.idle": "2024-07-07T15:17:25.990098Z",
          "shell.execute_reply.started": "2024-07-07T15:17:25.944909Z",
          "shell.execute_reply": "2024-07-07T15:17:25.988719Z"
        },
        "trusted": true,
        "id": "svGjgtKi8bz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:22:56.302168Z",
          "iopub.execute_input": "2024-07-07T15:22:56.302758Z",
          "iopub.status.idle": "2024-07-07T15:23:18.174459Z",
          "shell.execute_reply.started": "2024-07-07T15:22:56.302718Z",
          "shell.execute_reply": "2024-07-07T15:23:18.172638Z"
        },
        "trusted": true,
        "id": "nNYwKI458bz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:37:52.506878Z",
          "iopub.execute_input": "2024-07-07T15:37:52.507422Z",
          "iopub.status.idle": "2024-07-07T15:37:52.513911Z",
          "shell.execute_reply.started": "2024-07-07T15:37:52.507386Z",
          "shell.execute_reply": "2024-07-07T15:37:52.512326Z"
        },
        "trusted": true,
        "id": "VooOf8cC8bz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '//kaggle/input/auto-mpg/'\n",
        "files = os.listdir(dataset_path)\n",
        "print(files)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:37:55.011919Z",
          "iopub.execute_input": "2024-07-07T15:37:55.012377Z",
          "iopub.status.idle": "2024-07-07T15:37:55.023244Z",
          "shell.execute_reply.started": "2024-07-07T15:37:55.01234Z",
          "shell.execute_reply": "2024-07-07T15:37:55.021714Z"
        },
        "trusted": true,
        "id": "lwwS4q7P8bz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'auto-mpg.data.txt'\n",
        "dataset_path = os.path.join(dataset_path, dataset_name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:39:59.578534Z",
          "iopub.execute_input": "2024-07-07T15:39:59.579055Z",
          "iopub.status.idle": "2024-07-07T15:39:59.585746Z",
          "shell.execute_reply.started": "2024-07-07T15:39:59.579018Z",
          "shell.execute_reply": "2024-07-07T15:39:59.583984Z"
        },
        "trusted": true,
        "id": "_UOgTAA_8bz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file into a DataFrame\n",
        "dataset = pd.read_csv(dataset_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:41:15.85229Z",
          "iopub.execute_input": "2024-07-07T15:41:15.852775Z",
          "iopub.status.idle": "2024-07-07T15:41:15.865752Z",
          "shell.execute_reply.started": "2024-07-07T15:41:15.852736Z",
          "shell.execute_reply": "2024-07-07T15:41:15.864221Z"
        },
        "trusted": true,
        "id": "vzqymcZf8bz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T15:41:32.307003Z",
          "iopub.execute_input": "2024-07-07T15:41:32.307459Z",
          "iopub.status.idle": "2024-07-07T15:41:32.346668Z",
          "shell.execute_reply.started": "2024-07-07T15:41:32.307426Z",
          "shell.execute_reply": "2024-07-07T15:41:32.345133Z"
        },
        "trusted": true,
        "id": "kOJHERGf8b0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names, na_values= \"*\", comment='\\t', sep=\" \", skipinitialspace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:06:33.381683Z",
          "iopub.execute_input": "2024-07-07T16:06:33.383001Z",
          "iopub.status.idle": "2024-07-07T16:06:33.393977Z",
          "shell.execute_reply.started": "2024-07-07T16:06:33.382956Z",
          "shell.execute_reply": "2024-07-07T16:06:33.392563Z"
        },
        "trusted": true,
        "id": "1omg2_ul8b0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = raw_dataset.copy()\n",
        "dataset.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:06:38.649802Z",
          "iopub.execute_input": "2024-07-07T16:06:38.650758Z",
          "iopub.status.idle": "2024-07-07T16:06:38.68211Z",
          "shell.execute_reply.started": "2024-07-07T16:06:38.650723Z",
          "shell.execute_reply": "2024-07-07T16:06:38.680777Z"
        },
        "trusted": true,
        "id": "4MaOdQZY8b0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.tail()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:14:06.171641Z",
          "iopub.execute_input": "2024-07-07T16:14:06.172162Z",
          "iopub.status.idle": "2024-07-07T16:14:06.202828Z",
          "shell.execute_reply.started": "2024-07-07T16:14:06.172123Z",
          "shell.execute_reply": "2024-07-07T16:14:06.201515Z"
        },
        "trusted": true,
        "id": "r8fSax_x8b0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "Looking into data to understand the pattern and find missing or override to make data more impactful"
      ],
      "metadata": {
        "id": "q5VV-LsR8b0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:08:34.292486Z",
          "iopub.execute_input": "2024-07-07T16:08:34.292991Z",
          "iopub.status.idle": "2024-07-07T16:08:34.304142Z",
          "shell.execute_reply.started": "2024-07-07T16:08:34.292954Z",
          "shell.execute_reply": "2024-07-07T16:08:34.302812Z"
        },
        "trusted": true,
        "id": "G-o-ejh68b0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset= dataset.dropna()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:09:01.267339Z",
          "iopub.execute_input": "2024-07-07T16:09:01.267807Z",
          "iopub.status.idle": "2024-07-07T16:09:01.275004Z",
          "shell.execute_reply.started": "2024-07-07T16:09:01.267775Z",
          "shell.execute_reply": "2024-07-07T16:09:01.273764Z"
        },
        "trusted": true,
        "id": "0pLTLBKj8b0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the dataset has already been read into the DataFrame 'dataset'\n",
        "# Example:\n",
        "# dataset = pd.read_csv(file_path, sep=' ')\n",
        "\n",
        "# Ensure that the 'origin' column is present in the dataset\n",
        "if 'Origin' in dataset.columns:\n",
        "    # Create dummy variables for the 'origin' column\n",
        "    origin_dummies = pd.get_dummies(dataset['Origin'], prefix='Origin')\n",
        "\n",
        "    # Rename the columns to match 'USA', 'Europe', and 'Japan'\n",
        "    origin_dummies.columns = ['USA', 'Europe', 'Japan']\n",
        "\n",
        "    # Add the dummy columns to the original dataset\n",
        "    dataset = pd.concat([dataset, origin_dummies], axis=1)\n",
        "\n",
        "    # Optionally, drop the original 'origin' column if no longer needed\n",
        "    dataset.drop('Origin', axis=1, inplace=True)\n",
        "\n",
        "    # Display the first few rows of the dataset to verify the new columns\n",
        "    print(dataset.head())\n",
        "else:\n",
        "    print(\"The 'Origin' column is not present in the dataset.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:24:12.341394Z",
          "iopub.execute_input": "2024-07-07T16:24:12.34188Z",
          "iopub.status.idle": "2024-07-07T16:24:12.381558Z",
          "shell.execute_reply.started": "2024-07-07T16:24:12.341844Z",
          "shell.execute_reply": "2024-07-07T16:24:12.380233Z"
        },
        "trusted": true,
        "id": "Dtw9j2Oy8b0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['USA'] = (dataset['Origin'] == 1).astype(float)\n",
        "dataset['Europe'] = (dataset['Origin'] == 2).astype(float)\n",
        "dataset['Japan'] = (dataset['Origin'] == 3).astype(float)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:25:31.89294Z",
          "iopub.execute_input": "2024-07-07T16:25:31.893887Z",
          "iopub.status.idle": "2024-07-07T16:25:32.116717Z",
          "shell.execute_reply.started": "2024-07-07T16:25:31.893849Z",
          "shell.execute_reply": "2024-07-07T16:25:32.114998Z"
        },
        "trusted": true,
        "id": "N-3rTmkS8b0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training and evloution\n",
        "\n",
        "We need to split the data into training set and testing set"
      ],
      "metadata": {
        "id": "dCypiWAE8b0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:28:47.624833Z",
          "iopub.execute_input": "2024-07-07T16:28:47.625787Z",
          "iopub.status.idle": "2024-07-07T16:28:47.639834Z",
          "shell.execute_reply.started": "2024-07-07T16:28:47.625712Z",
          "shell.execute_reply": "2024-07-07T16:28:47.638185Z"
        },
        "trusted": true,
        "id": "6cRb1xQZ8b0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Undestand the data:\n",
        "lets inspect the data at the joint distribution of a few pairs of columns from the trainig set,"
      ],
      "metadata": {
        "id": "iAPyJ4tM8b0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot((train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:31:02.385789Z",
          "iopub.execute_input": "2024-07-07T16:31:02.386247Z",
          "iopub.status.idle": "2024-07-07T16:31:02.397765Z",
          "shell.execute_reply.started": "2024-07-07T16:31:02.386215Z",
          "shell.execute_reply": "2024-07-07T16:31:02.395672Z"
        },
        "trusted": true,
        "id": "uPpOkARb8b0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:31:25.897969Z",
          "iopub.execute_input": "2024-07-07T16:31:25.89847Z",
          "iopub.status.idle": "2024-07-07T16:31:31.703155Z",
          "shell.execute_reply.started": "2024-07-07T16:31:25.898433Z",
          "shell.execute_reply": "2024-07-07T16:31:31.701808Z"
        },
        "trusted": true,
        "id": "OMLReZeZ8b0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:34:15.867729Z",
          "iopub.execute_input": "2024-07-07T16:34:15.868209Z",
          "iopub.status.idle": "2024-07-07T16:34:15.926503Z",
          "shell.execute_reply.started": "2024-07-07T16:34:15.868179Z",
          "shell.execute_reply": "2024-07-07T16:34:15.925359Z"
        },
        "trusted": true,
        "id": "yzcqpjf68b0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect the feature and split from labels\n",
        "\n",
        "we need to identify the target value from features and seperate the target values. The label is useful in train the model to predict."
      ],
      "metadata": {
        "id": "jj54c6mB8b0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_dataset.pop('MPG')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:37:19.490251Z",
          "iopub.execute_input": "2024-07-07T16:37:19.491539Z",
          "iopub.status.idle": "2024-07-07T16:37:19.498332Z",
          "shell.execute_reply.started": "2024-07-07T16:37:19.491499Z",
          "shell.execute_reply": "2024-07-07T16:37:19.496952Z"
        },
        "trusted": true,
        "id": "W5RxeVzu8b0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = test_dataset.pop('MPG')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:38:12.827902Z",
          "iopub.execute_input": "2024-07-07T16:38:12.828336Z",
          "iopub.status.idle": "2024-07-07T16:38:12.835201Z",
          "shell.execute_reply.started": "2024-07-07T16:38:12.828289Z",
          "shell.execute_reply": "2024-07-07T16:38:12.833509Z"
        },
        "trusted": true,
        "id": "1KGK6tMz8b0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Normalization:\n",
        "\n",
        "Normalizing data is a common preprocessing step in data analysis and machine learning that involves transforming data to a common scale without distorting differences in the ranges of values. Normalization ensures that each feature contributes equally to the analysis, preventing any single feature from dominating due to its scale. Here are several reasons why normalizing data is considered a good practice:\n",
        "1. Improves Convergence in Gradient Descent\n",
        "\n",
        "    Reason: Gradient descent algorithms, commonly used in training machine learning models, converge faster when the data is normalized.\n",
        "    Explanation: When features are on different scales, the cost function contours can be elongated, causing the algorithm to oscillate and take longer to find the minimum. Normalized data typically results in more circular contours, leading to faster convergence.\n",
        "\n",
        "2. Ensures Fair Comparison of Features\n",
        "\n",
        "    Reason: Normalization ensures that features with larger magnitudes do not dominate the learning process.\n",
        "    Explanation: Without normalization, features with larger ranges can disproportionately influence the model's predictions, leading to biased results. Normalizing allows each feature to contribute equally.\n",
        "\n",
        "3. Improves Model Performance\n",
        "\n",
        "    Reason: Many machine learning algorithms, such as k-nearest neighbors (KNN) and support vector machines (SVM), perform better with normalized data.\n",
        "    Explanation: These algorithms rely on distance metrics. If features are on different scales, the distance calculations may become skewed, leading to inaccurate predictions.\n",
        "\n",
        "4. Stabilizes Numerical Computations\n",
        "\n",
        "    Reason: Normalizing data can prevent numerical instability in algorithms that involve matrix operations.\n",
        "    Explanation: Large ranges in data can cause numerical instability, leading to overflow or underflow issues in computations. Normalized data typically results in more stable numerical operations.\n",
        "\n",
        "5. Enhances Interpretability\n",
        "\n",
        "    Reason: Normalized data makes it easier to interpret model coefficients and feature importance.\n",
        "    Explanation: When data is normalized, the model coefficients can be directly compared to understand the relative importance of each feature.\n",
        "\n",
        "Common Normalization Techniques\n",
        "\n",
        "    Min-Max Scaling:\n",
        "        Rescales the data to a fixed range, usually 0 to 1.\n",
        "        Formula: X′=X−XminXmax−XminX′=Xmax​−Xmin​X−Xmin​​\n",
        "\n",
        "    Standardization (Z-score normalization):\n",
        "        Rescales data to have a mean of 0 and a standard deviation of 1.\n",
        "        Formula: X′=X−μσX′=σX−μ​\n",
        "\n",
        "    Max Abs Scaling:\n",
        "        Scales each feature by its maximum absolute value.\n",
        "        Formula: X′=X∣Xmax∣X′=∣Xmax​∣X​\n",
        "\n",
        "    Robust Scaling:\n",
        "        Scales data using statistics that are robust to outliers, such as median and interquartile range.\n",
        "        Formula: X′=X−medianIQRX′=IQRX−median​"
      ],
      "metadata": {
        "id": "fJdbL77-8b0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(X):\n",
        "    return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "#normed_train_data = norm(train_dataset)\n",
        "#normed_test_data = norm(test_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:47:15.912707Z",
          "iopub.execute_input": "2024-07-07T16:47:15.913173Z",
          "iopub.status.idle": "2024-07-07T16:47:15.920076Z",
          "shell.execute_reply.started": "2024-07-07T16:47:15.913138Z",
          "shell.execute_reply": "2024-07-07T16:47:15.918499Z"
        },
        "trusted": true,
        "id": "UnLm83br8b0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normed_train_data = norm(train_dataset)\n",
        "#normed_test_data = norm(test_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-07T16:47:29.950457Z",
          "iopub.execute_input": "2024-07-07T16:47:29.950971Z",
          "iopub.status.idle": "2024-07-07T16:47:30.039563Z",
          "shell.execute_reply.started": "2024-07-07T16:47:29.950936Z",
          "shell.execute_reply": "2024-07-07T16:47:30.037648Z"
        },
        "trusted": true,
        "id": "qAXwgLBm8b0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_dr5u_P8b0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}